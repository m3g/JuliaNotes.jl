var documenterSearchIndex = {"docs":
[{"location":"instability/#Type-instability-and-performance","page":"Type instability","title":"Type instability and performance","text":"","category":"section"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"To obtain a performant code it is important that the types of the variables can be inferred by the compiler. If a variable can change type in an unpredictable manner, we say that there is a type instability.","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"Type instabilities generally occur when we try to use global variables inside functions, that is, without passing these variables as parameters to the functions. Lets explain that. ","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"A global variable is anything defined in the global scope, that is outside any function or other structure that defines a scope (let blocks, for example). We obtain a global variable when writing, in the REPL, ","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"julia> x = 5. ","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"or when we write in a script the same thing:","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"more script.jl","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"x = 5.","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"A variable defined in this way is type unstable because you can change its value at any time to anything. For example,","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"julia> x = 5.\n5.0\n\njulia> x = \"ABC\"\n\"ABC\"\n","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"Now, we will define a function that uses the value of x without passing x as a parameter. This function will sum up the elements of x:","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"julia> function f()\n            s = 0\n            for val in x\n              s = s + val\n            end\n            return s\n       end\nf (generic function with 1 method)\n","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"This function cannot be specialized for the type of variable that x is, because, as we have mentioned, x could be any type of variable.  This problem can be tracked with the macro @code_warntype: ","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"julia> @code_warntype f()\nVariables\n  #self#::Core.Compiler.Const(f, false)\n  s::Any\n  @_3::Any\n  val::Any\n\nBody::Any\n1 ─       (s = 0.0)\n│   %2  = Main.x::Any\n│         (@_3 = Base.iterate(%2))\n│   %4  = (@_3 === nothing)::Bool\n│   %5  = Base.not_int(%4)::Bool\n└──       goto #4 if not %5\n2 ┄ %7  = @_3::Any\n│         (val = Core.getfield(%7, 1))\n│   %9  = Core.getfield(%7, 2)::Any\n│         (s = s + val)\n│         (@_3 = Base.iterate(%2, %9))\n│   %12 = (@_3 === nothing)::Bool\n│   %13 = Base.not_int(%12)::Bool\n└──       goto #4 if not %13\n3 ─       goto #2\n4 ┄       return s\n\n","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"Note that there are many Any in the code above, which will be highlighted in red if you run these commands in your REPL. That indicates that something is not quite right. In particular, note the line Body::Any: it indicates that the result of the body of that function can be of any type, in principle.    ","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"Let us check how this function performs. We will define x as a vector of many components such that the time of f(x) is measured accurately:","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"julia> x = rand(1000);\n\njulia> @btime f()\n  60.148 μs (3490 allocations: 70.16 KiB)\n492.360646736646\n","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"Now, we will define a new function that receives x as a parameter, and besides that does exactly the same thing:","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"julia> function g(x)\n           s = zero(eltype(x))\n           for val in x\n              s = s + val\n           end\n           return s\n       end\n","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"In this example we were obsessive by initializing s as zero(eltype(x)), which indicates that s is a zero of the same type of the elements of x. That is, if x is a vector of integer numbers, s will be 0 (integer), and if x is a vector of real numbers, s will be 0. (real). This is not fundamental for the performance here tested, but it will eliminate all possible types of instability of the variables within that code.  ","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"Now, if we call g(x) with a x of a specific type, that will create a method of that function specialized for this type of variable. For example, if we call g with the number 1, which is an integer number, all operations in g will be performed with integers:","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"julia> @code_warntype g(1)\nVariables\n  #self#::Core.Compiler.Const(g, false)\n  x::Int64\n  s::Int64\n  @_4::Union{Nothing, Tuple{Int64,Nothing}}\n  val::Int64\n\nBody::Int64\n1 ─       (s = 0)\n│   %2  = x::Int64\n│         (@_4 = Base.iterate(%2))\n│   %4  = (@_4::Tuple{Int64,Nothing} === nothing)::Core.Compiler.Const(false, false)\n│   %5  = Base.not_int(%4)::Core.Compiler.Const(true, false)\n└──       goto #4 if not %5\n2 ─ %7  = @_4::Tuple{Int64,Nothing}::Tuple{Int64,Nothing}\n│         (val = Core.getfield(%7, 1))\n│   %9  = Core.getfield(%7, 2)::Core.Compiler.Const(nothing, false)\n│         (s = s::Core.Compiler.Const(0, false) + val)\n│         (@_4 = Base.iterate(%2, %9))\n│   %12 = (@_4::Core.Compiler.Const(nothing, false) === nothing)::Core.Compiler.Const(true, false)\n│   %13 = Base.not_int(%12)::Core.Compiler.Const(false, false)\n└──       goto #4 if not %13\n3 ─       Core.Compiler.Const(:(goto %7), false)\n4 ┄       return s\n","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"Note that there is no Any remaiing in the above code and that, in particular, the result of the body of the code is guaranteed to be an integer Body::Int64. ","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"If we call the same function with the number 3.14, which is real, another method is generated:","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"julia> @code_warntype g(3.14)\nVariables\n  #self#::Core.Compiler.Const(g, false)\n  x::Float64\n  s::Float64\n  @_4::Union{Nothing, Tuple{Float64,Nothing}}\n  val::Float64\n\nBody::Float64\n1 ─       (s = 0)\n│   %2  = x::Float64\n│         (@_4 = Base.iterate(%2))\n│   %4  = (@_4::Tuple{Float64,Nothing} === nothing)::Core.Compiler.Const(false, false)\n│   %5  = Base.not_int(%4)::Core.Compiler.Const(true, false)\n└──       goto #4 if not %5\n2 ─ %7  = @_4::Tuple{Float64,Nothing}::Tuple{Float64,Nothing}\n│         (val = Core.getfield(%7, 1))\n│   %9  = Core.getfield(%7, 2)::Core.Compiler.Const(nothing, false)\n│         (s = s::Core.Compiler.Const(0, false) + val)\n│         (@_4 = Base.iterate(%2, %9))\n│   %12 = (@_4::Core.Compiler.Const(nothing, false) === nothing)::Core.Compiler.Const(true, false)\n│   %13 = Base.not_int(%12)::Core.Compiler.Const(false, false)\n└──       goto #4 if not %13\n3 ─       Core.Compiler.Const(:(goto %7), false)\n4 ┄       return s::Float64\n","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"Now all types of the function are Float64 and the function is guaranteed to return that type of number.","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"This specialization was not possible when x was not a parameter of the function, because the method had to deal with any type of variables.","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"How the performance of these methods compare with the previous implementation that had type instabilities? Let us see:","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"julia> x = rand(1000);\n\njulia> @btime f()\n  59.518 μs (3490 allocations: 70.16 KiB)\n504.23960342930764\n\njulia> @btime g($x)\n  965.300 ns (0 allocations: 0 bytes)\n504.23960342930764\n","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"The function g is about 60 times faster than f and, furthermore, does not allocate any memory. ","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"To guarantee that function are type-stable, therefore, is one of the most important things in the generation of fast code.","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"Global variables, therefore, must be avoided inside functions. They must be passed as parameters such that specialized methods can be built. ","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"Sometimes, however, the values are constants. For example, pi. It would be strange to have to pass pi as a parameter to every function that uses it. Thus, pi is a constant-global, and being a constant it does not introduce type-instabilities. Custom constant global are defined with the const keyword, and solve the performance issue of the function f above.","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"julia> const x = rand(1000);\n\njulia> @btime f()\n  963.300 ns (0 allocations: 0 bytes)\n504.11877716593017\n","category":"page"},{"location":"instability/","page":"Type instability","title":"Type instability","text":"Yet, in this case calling the variable x a constant is artificial, and in this particular case the function f only computes the sum of the elements of that particular x from now on. Thus, it is much more reasonable to pass x as a parameter, and let the constants be used for actual constant values, as pi.         ","category":"page"},{"location":"assignment/#Assignment-and-mutation","page":"Assignment and mutation","title":"Assignment and mutation","text":"","category":"section"},{"location":"assignment/","page":"Assignment and mutation","title":"Assignment and mutation","text":"From: Assignment and mutation","category":"page"},{"location":"assignment/","page":"Assignment and mutation","title":"Assignment and mutation","text":"The simplest version of this Stephan Karpinksy can come up with is this:","category":"page"},{"location":"assignment/","page":"Assignment and mutation","title":"Assignment and mutation","text":"Assignment changes which object a name refers to: x = ex causes the name x to refer to the value resulting from the evaluation of the expression ex. Assignment never changes the values of any objects.\nMutation changes the value of an object: x[i] = ex and x.f = ex both mutate the object referred to by x changing a value at index or a property with a name, respectively. Mutation never changes what objects any names in any scope refer to.","category":"page"},{"location":"assignment/","page":"Assignment and mutation","title":"Assignment and mutation","text":"Perhaps the confusion comes from the fact that these all use the = in their syntax? They’re really totally unrelated. It’s also possible that people think of assignment as setting a named property on some implicit “scope object”. That’s probably a view that can be worked out coherently, in which case having a clear notion of what all the different “scope objects” are would be crucial but I’m not entirely sure if that’s a helpful way to think about the matter or not.","category":"page"},{"location":"assignment/","page":"Assignment and mutation","title":"Assignment and mutation","text":"In summary:","category":"page"},{"location":"assignment/","page":"Assignment and mutation","title":"Assignment and mutation","text":"x=[2]  # x points to memory location m1\ny=x    # y points to memory location m1\nx=[3]  # x points to memory location m2, y still points to m1\nz=x    # z points to memory location m2\nx[1]=4 # m2 changes value in place, affecting all variables that point there","category":"page"},{"location":"assignment/","page":"Assignment and mutation","title":"Assignment and mutation","text":"julia> println(x,y,z)\n[4][2][4]\n","category":"page"},{"location":"assignment/#Another-way-to-put-it:","page":"Assignment and mutation","title":"Another way to put it:","text":"","category":"section"},{"location":"assignment/","page":"Assignment and mutation","title":"Assignment and mutation","text":"That admittedly is confusing at the beginning. One gets used to it, though, and after that one notes that actually there is no way out from that if one wants to have a dynamically typed language.","category":"page"},{"location":"assignment/","page":"Assignment and mutation","title":"Assignment and mutation","text":"The fact that the language is dynamic requires that we can do ","category":"page"},{"location":"assignment/","page":"Assignment and mutation","title":"Assignment and mutation","text":"julia> x = [1,2]\n2-element Array{Int64,1}:\n 1\n 2\n\njulia> x = π\nπ = 3.1415926535897...\n","category":"page"},{"location":"assignment/","page":"Assignment and mutation","title":"Assignment and mutation","text":"That is completely natural, but means that = is just the binding of a name to a value (which might be an array, or scalar, or whatever). ","category":"page"},{"location":"assignment/","page":"Assignment and mutation","title":"Assignment and mutation","text":"Thus, we need to be able to differentiate naming something from mutating something. Mutating is a function that acts on a mutable object. It is the setindex! function:","category":"page"},{"location":"assignment/","page":"Assignment and mutation","title":"Assignment and mutation","text":"julia> x = [1,2]\n2-element Array{Int64,1}:\n 1\n 2\n\njulia> setindex!(x,10,1)\n2-element Array{Int64,1}:\n 10\n  2","category":"page"},{"location":"assignment/","page":"Assignment and mutation","title":"Assignment and mutation","text":"Which, by convenience (obviously) can be called with the notation:","category":"page"},{"location":"assignment/","page":"Assignment and mutation","title":"Assignment and mutation","text":"julia> x[1] = 10\n10\n","category":"page"},{"location":"assignment/","page":"Assignment and mutation","title":"Assignment and mutation","text":"But this last x[1] = 10 is a call to setindex!, not a name assignment as the other cases. (and a broadcasting of assignments, with .=, is just a loop calling setindex! for each element)","category":"page"},{"location":"nomethod/#ERROR:-MethodError:-no-method-matching....","page":"ERROR: No method...","title":"ERROR: MethodError: no method matching....","text":"","category":"section"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"This is a common error message, which is related to one of the most fundamental characteristics of the Julia language: multiple dispatch.  Multiple dispatch is the specialization of a function to every one of its arguments.  ","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"For example, if we define the following function:","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"julia> f(x,y) = 2*x + y\nf (generic function with 1 method)","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"We have a function that can receive different types of variables (such as scalar integers or floats, or vectors, etc.). This function will be specialized for each type of variables on input. The @code_typed macro displays what the codes becomes after the type-specialization of the variables. For example, with integers, we have:","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"julia> @code_typed f(1,1)\nCodeInfo(\n1 ─ %1 = Base.mul_int(2, x)::Int64\n│   %2 = Base.add_int(%1, y)::Int64\n└──      return %2\n) => Int64","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"Note that the function calls Base.mul_int and Base.add_int, which are specialized functions to multiply and add integer numbers. ","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"If we call the same function with real numbers, we have, first a conversion of the number 2 from integer to float, and then specialized functions are called to multiply and add these floating point numbers:","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"julia> @code_typed f(1.0,1.0)\nCodeInfo(\n1 ─ %1 = Base.sitofp(Float64, 2)::Float64\n│   %2 = Base.mul_float(%1, x)::Float64\n│   %3 = Base.add_float(%2, y)::Float64\n└──      return %3\n) => Float64","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"Therefore, the code of f(x,y) was specialized, at execution time, to different types of variables, and will produce fast compiled versions of the code in each case. ","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"We can define functions for which we restrict the types of variables accepted. For example, let us define a function that only accepts numbers, but not vectors:","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"julia> g(x::Number,y::Number) = 2*x + y\ng (generic function with 1 method)\n\njulia> g(1,1)\n3\n\njulia> g(1.0,1.0)\n3.0\n","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"For now the function is exactly the same as the previous f(x,y).","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"The function f(x,y) could, however, accept vectors as parameters:","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"julia> x = [1,1]; y = [2,2];\n\njulia> f(x,y)\n2-element Array{Int64,1}:\n 4\n 4\n","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"However, g(x,y) is called with vectors as arguments, we now have an error:    ","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"julia> g(x,y)\nERROR: MethodError: no method matching g(::Array{Int64,1}, ::Array{Int64,1})\nStacktrace:\n [1] top-level scope at REPL[9]:1\n","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"The error is quite explicit: there is no definition of the function g which is intended to accept arrays as parameters.   ","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"Therefore, if you got one error of this type in your program, that means that some function is being call with the wrong arguments. That might mean the argument of the incorrect type, or the wrong number of arguments. For example:","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"julia> f(x)\nERROR: MethodError: no method matching f(::Array{Int64,1})\nClosest candidates are:\n  f(::Any, ::Any) at REPL[1]:1\nStacktrace:\n [1] top-level scope at REPL[10]:1\n","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"Debug your code to find where this error occurs, and check each parameter being fed to the function. Compare it with the definitions of the methods of that function, if necessary. The methods of a function can be listed, for example, with:","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"julia> methods(g)\n# 1 method for generic function \"g\":\n[1] g(x::Number, y::Number) in Main at REPL[4]:1\n","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"Why, then, one would restrict the type of variable a function can receive? There are two reasons for that: 1) Make the code clearer to the user, by specifying the type of variable that a function is expected to receive and 2) Anticipate an error.  For example, the function f can receive two vectors because the sum of two vectors is well defined.  However, the sum of a vector with a scalar is not. Therefore,","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"julia> x = [1,1]; y = 2;\n\njulia> f(x,y)\nERROR: MethodError: no method matching +(::Array{Int64,1}, ::Int64)\nFor element-wise addition, use broadcasting with dot syntax: array .+\nscalar\n","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"We get a method error here because the sum of a scalar with an array is not defined. We could have anticipated that error in our function by accepting only numbers (as in our definition of g), only vectors, or, more interestingly, only elements of the same type:","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"julia> h(x::T, y::T) where T = 2*x + y\nh (generic function with 1 method)\n","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"Now T is a parametric type, and we only require that x and y are of the same type T. Now, we have:","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"julia> h(1,1)\n3\n\njulia> x = [1,1]; y = [2,2];\n\njulia> h(x,y)\n2-element Array{Int64,1}:\n 4\n 4\n\njulia> x = [1,1]; y = 2;\n\njulia> h(x,y)\nERROR: MethodError: no method matching h(::Array{Int64,1}, ::Int64)\n","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"We only get an error if the two types are different, in which case the addition is not defined. And the error occurs not in the call to the + function, as with the function f, but in the call to h, anticipating the error and, perhaps, facilitating the debugging of the program. ","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"Alternativelly, we could have defined a new method to the function g, accepting only vectors:","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"julia> g(x::Vector, y::Vector) = 2*x + y\ng (generic function with 2 methods)\n","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"Note that g has now two methods:","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"julia> methods(g)\n# 2 methods for generic function \"g\":\n[1] g(x::Number, y::Number) in Main at REPL[4]:1\n[2] g(x::Array{T,1} where T, y::Array{T,1} where T) in Main at\nREPL[21]:1\n","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"One of these methods only accepts scalars, the other only accepts arrays. The most specific method for the type of variable being provided to the function will be used. This can be seen, for example, with the function f. Currently, it has only one method without any type specification:  ","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"julia> methods(f)\n# 1 method for generic function \"f\":\n[1] f(x, y) in Main at REPL[1]:1\n","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"Of course the function f cannot receive strings. However, we can define a new method for f which does receive strings:  ","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"julia> f(x::String, y::String) = \"$x $x $y\"\nf (generic function with 2 methods)\n\njulia> f(\"abc\",\"def\")\n\"abc abc def\"\n","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"We defined a method for f which does more or less what one would expect from 2x + y with strings, and this method is now invoked if f receives two strings as input, despite the other method being completely general. That is, the most specific method was invoked. ","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"More interestingly, we can define a method for f which actually performs what one could expect from the syntax associated to the addition of a vector and a scalar (which, if meaning anything, probably should mean summing the scalar to every element of the vector):","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"julia> f(x::Vector, y::Number) = 2*x .+ y\nf (generic function with 3 methods)\n\njulia> x = [1,1]; y=2\n2\n\njulia> f(x,y)\n2-element Array{Int64,1}:\n 4\n 4\n","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"Note the . in the definition of the sum, which is the broadcast operator, which implies that the sum will be performed for every element of x. ","category":"page"},{"location":"nomethod/","page":"ERROR: No method...","title":"ERROR: No method...","text":"Of course, it is always recommended to define methods that perform conceptually the same thing, but with different types of variables, for the same function.  ","category":"page"},{"location":"publish_docs/#How-to-deploy-the-documentation-of-a-project","page":"Publish Docs","title":"How to deploy the documentation of a project","text":"","category":"section"},{"location":"publish_docs/#Visualize-the-Docs-locally","page":"Publish Docs","title":"Visualize the Docs locally","text":"","category":"section"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"The best tool I know for that is LiveServer and its servedocs() function. Just do:","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"julia> ] activate docs\n\njulia> using LiveServer \n\njulia> servedocs()","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"and the docs will be rendered and hosted locally at the url provided in the output.","category":"page"},{"location":"publish_docs/#Use-DocumenterTools-to-generate-the-keys","page":"Publish Docs","title":"Use DocumenterTools to generate the keys","text":"","category":"section"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"import DocumenterTools\nDocumenterTools.genkeys()","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"which will output something like:","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"julia> DocumenterTools.genkeys()\n[ Info: add the public key below to https://github.com/$USER/$REPO/settings/keys with read/write access:\n\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDIIDDRX8DyLG... CCKQPTNei1Ng8b5d+a1ldnVSkgB0= Documenter\n\n[ Info: add a secure environment variable named 'DOCUMENTER_KEY' to https://travis-ci.com/$USER/$REPO/settings (if you deploy using Travis CI) or https://github.com/$USER/$REPO/settings/secrets (if you deploy using GitHub Actions) with value:\n\nLS0tLS1CRUdJTiBPUEVOU1NIIFBSSV... MGtyNng2VWR6WTFxckg1bkUyVGU2ajU3TUdveXpZL1EzTApoNGlqbE5NSWJTOFA2K2JNUkYxVFVCUzdQbC9mZDlTZWJKYTlKdWpMamtnNWRiblJFSkpESmpDTzNzSjZ4d0VCUmV2WmJSCnZtV2lkWkVnQnlPUFVsQUFBQUNrUnZZM1Z0Wlc1MFpYST0KLS0tLS1FTkQgT1BFTlNTSCBQUklWQVRFIEtFWS0tLS0tCg==","category":"page"},{"location":"publish_docs/#Add-the-keys-to-the-github-repository","page":"Publish Docs","title":"Add the keys to the github repository","text":"","category":"section"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"The first key, starting with ssh-rsa must be copied as a new \"Deploy key` in the project, at: ","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"Settings -> Deploy keys -> Add deploy key","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"Be careful in allowing Write permissions. The second key has to be copied to:","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"Settings -> Secrets -> Actions -> New repository secret ","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"with the name DOCUMENTER_KEY.","category":"page"},{"location":"publish_docs/#Add-the-GithubActions-(ci.yml)-workflow-file","page":"Publish Docs","title":"Add the GithubActions (ci.yml) workflow file","text":"","category":"section"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"Create, in your project, a file ","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"/home/user/.julia/dev/Project/.github/workflows/ci.yml","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"with a content similar to THIS one.","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"Note that you have to change some lines that contain the name of the package name (in the example the package is called CellListMap - two substitutions are required).","category":"page"},{"location":"publish_docs/#Create-a-release","page":"Publish Docs","title":"Create a release","text":"","category":"section"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"Go to the github page. Go to Releases rightarrow Draft a new Release. Create a new tag for the new version (for example, v0.2.0) or a tag only for deploying the documentation (for example, v0.1.0+doc1). That will trigger the execution of the CI run and, hopefully, build the docs and the gh-branch that contain the docs automatically. ","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"The pages will be hosted at, for example:","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"https://m3g.github.io/JuliaNotes.jl/stable/","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"You can also update the docs just by uploading a new tag, with:","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"git tag -a v0.1.0+doc2 -m \"v0.1.0\"\ngit push --tag","category":"page"},{"location":"publish_docs/#Create-an-empty-gh-pages-branch-and-choose-it-to-deploy-the-page","page":"Publish Docs","title":"Create an empty gh-pages branch and choose it to deploy the page","text":"","category":"section"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"I have seen these steps happening automatically after the tag is created. If not, follow the steps below. ","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"Create a branch on the repository called gh-pages using: ","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"git checkout --orphan gh-pages\ngit reset --hard\ngit commit --allow-empty -m \"Initializing gh-pages branch\"\ngit push origin gh-pages\ngit checkout main","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"In the GitHub repository, do:","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"Settings -> GitHub Pages -> choose gh-pages (/root)","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"(that is, go to Settings, scroll down, on the GitHub pages section, choose the gh-pages branch to deploy your page).","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"After the end of the CI run, if no error was detected, the site should be published.","category":"page"},{"location":"publish_docs/#For-a-registered-package","page":"Publish Docs","title":"For a registered package","text":"","category":"section"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"In this case, you might want TagBot to tag and release automatically the documentation of new versions:","category":"page"},{"location":"publish_docs/#Create-the-TagBot.yml-file","page":"Publish Docs","title":"Create the TagBot.yml file","text":"","category":"section"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"/home/user/.julia/dev/Project/.github/workflows/TagBot.yml","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"and add the content provided here: TagBot.yml example","category":"page"},{"location":"publish_docs/#Deployment-of-the-docs-of-a-previous-version","page":"Publish Docs","title":"Deployment of the docs of a previous version","text":"","category":"section"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"I went to the registered commit, which always have the following information, for example:","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"git tag -a v0.4.11 -m \"<description of version>\" fbeec6a00adbd15053d297542e8354c457b2a610\ngit push origin v0.4.11","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"and created a new tag adding +doc1 to the tag:","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"git tag -a v0.4.11+doc1 -m \"v0.4.11\" fbeec6a00adbd15053d297542e8354c457b2a610\ngit push origin v0.4.11+doc1","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"Then I had to go to the github page -> tags, and publish that release manually.","category":"page"},{"location":"publish_docs/","page":"Publish Docs","title":"Publish Docs","text":"Further discussion: Latest version of docs not published","category":"page"},{"location":"figures/#Some-tips-to-produce-beautiful-plots-with-Plots-and-LaTeX","page":"Figures and LaTeX","title":"Some tips to produce beautiful plots with Plots and LaTeX","text":"","category":"section"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"When using Plots, in particular in combination with the LaTeXStrings package, some tips can help one to obtain nice-looking fonts.","category":"page"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"Use LaTeXStrings to produce subscripts, math, etc.\nSet all fonts to ComputerModern by default. \nAdjust plot size. ","category":"page"},{"location":"figures/#LaTeX-fonts","page":"Figures and LaTeX","title":"LaTeX fonts","text":"","category":"section"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"Some other options, as linewidth, framestyle, are a matter of taste. Here I use what I usually prefer. ","category":"page"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"using Plots\nusing LaTeXStrings\nplot_font = \"Computer Modern\"\ndefault(\n    fontfamily=plot_font,\n    linewidth=2, \n    framestyle=:box, \n    label=nothing, \n    grid=false\n)\nplot(sort(rand(10)),sort(rand(10)),label=\"Legend\")\nplot!(xlabel=L\"\\textrm{Standard~text}(r) / \\mathrm{cm^3}\")\nplot!(ylabel=\"Same font as everything\")\nannotate!(0.5,0.8,text(\"My note\",plot_font,12))","category":"page"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"This will produce a figure with homogeneous fonts:","category":"page"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"<img src=\"https://raw.githubusercontent.com/m3g/JuliaNotes.jl/main/docs/src/assets/plot1.png\">","category":"page"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"The font of annotations must be set explicitly, as in the example, for each annotation (they do not inherit the default font).","category":"page"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"The use of \\textrm or \\mathrm, which should provide the same results, must be tested, because of an an issue with TeX rendering by GR. Also, sometimes it is necessary to add ~ to represent spaces in \\textrm{} blocks, as in the example. ","category":"page"},{"location":"figures/#Font,-margin,-and-figure-size","page":"Figures and LaTeX","title":"Font, margin, and figure size","text":"","category":"section"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"The font and figure sizes can be tunned using some parameters, for instance, scalefontsizes:","category":"page"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"scalefontsizes(1.3)\nplot(sort(rand(10)),sort(rand(10)),label=\"Legend\")\nplot!(xlabel=L\"\\textrm{Standard~text}(r) / \\mathrm{cm^3}\")\nplot!(ylabel=\"Same font as everything\")\nannotate!(0.5,0.8,text(\"My note\",plot_font,12))","category":"page"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"Which will produce this figure:","category":"page"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"<img src=\"https://raw.githubusercontent.com/m3g/JuliaNotes.jl/main/docs/src/assets/plot2.png\">","category":"page"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"To control the margins, because sometimes depending on the font and figure sizes the labels might be cut, set margins (as in the example), which to be set practically need the explicit import of Plots.Measures, and perhaps play a little with the size (size parameter) of the figure. For example:","category":"page"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"using Plots, Plots.Measures, LaTeXStrings\nplot_font = \"Computer Modern\"\ndefault(\n    fontfamily=plot_font,\n    linewidth=2, \n    framestyle=:box, \n    label=nothing, \n    grid=false\n)\nscalefontsizes(1.5)\nplot(sort(rand(10)),sort(rand(10)),label=\"Legend\")\nplot!(xlabel=L\"\\textrm{Standard~text}(r) / \\mathrm{cm^3}\")\nplot!(ylabel=\"Same font as everything\")\nannotate!(0.5,0.8,text(\"My note\",plot_font,12))\nplot!(margin=(5mm),size=(500,400))","category":"page"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"will produce:","category":"page"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"<img src=\"https://raw.githubusercontent.com/m3g/JuliaNotes.jl/main/docs/src/assets/plot3.png\">","category":"page"},{"location":"figures/#Save-as-PDF,-convert-afterwards","page":"Figures and LaTeX","title":"Save as PDF, convert afterwards","text":"","category":"section"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"As a reasonable strategy, it is practical to save the plot to a pdf file, with ","category":"page"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"savefig(\"./plot.pdf\")","category":"page"},{"location":"figures/","page":"Figures and LaTeX","title":"Figures and LaTeX","text":"and convert it later to other formats (png, tiff, etc), with, for example GIMP. PDF are scalable vector graphics, thus the resolution will be defined only on the conversion step. Additionally, PDF viewers update the file when it is modified, thus one can tune the figure properties by changing the plot generation and viewing the PDF directly, which we will be sure will conform the final figure appearance.   ","category":"page"},{"location":"new_package/#How-to-create-a-new-package","page":"Create new package","title":"How to create a new package","text":"","category":"section"},{"location":"new_package/#Create-the-github-repository","page":"Create new package","title":"Create the github repository","text":"","category":"section"},{"location":"new_package/","page":"Create new package","title":"Create new package","text":"Create an EMPTY repository on github, with your package name followed by .jl. For example: ","category":"page"},{"location":"new_package/","page":"Create new package","title":"Create new package","text":"https://github.com/lmiq/MyPackage.jl","category":"page"},{"location":"new_package/#Use-PkgTemplates-to-create-the-minimal-package-structure:","page":"Create new package","title":"Use PkgTemplates to create the minimal package structure:","text":"","category":"section"},{"location":"new_package/","page":"Create new package","title":"Create new package","text":"using PkgTemplates\ntpl = Template(user=\"lmiq\")\ntpl(\"MyPackage\")","category":"page"},{"location":"new_package/","page":"Create new package","title":"Create new package","text":"This will create the .julia/dev/MyPackage directory with the content inside. ","category":"page"},{"location":"new_package/#Push-the-content-to-the-repository-for-the-first-time","page":"Create new package","title":"Push the content to the repository for the first time","text":"","category":"section"},{"location":"new_package/","page":"Create new package","title":"Create new package","text":"Navigate to the package directory, and push the content:","category":"page"},{"location":"new_package/","page":"Create new package","title":"Create new package","text":"cd ~/.julia/dev/MyPackage\ngit push --set-upstream origin main","category":"page"},{"location":"new_package/","page":"Create new package","title":"Create new package","text":"(main was master in older github repositories)","category":"page"},{"location":"new_package/","page":"Create new package","title":"Create new package","text":"(From: this thread). Another useful post, with some additional information on how to create the package using the Github Desktop, is available here. ","category":"page"},{"location":"modules/#Modules-and-Revise","page":"Modules and Revise","title":"Modules and Revise","text":"","category":"section"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"The most practical way to develop code in Julia, particularly when the code becomes more complex, is to write modules and use the Revise package.","category":"page"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"To install the Revise package, do:","category":"page"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"julia> ] add Revise","category":"page"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"The workflow is, then:","category":"page"},{"location":"modules/#Create-a-function","page":"Modules and Revise","title":"Create a function","text":"","category":"section"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"Create a file with a function, for example: f.jl","category":"page"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"function f(x)\n    y = 2*x\n    return y\nend","category":"page"},{"location":"modules/#Create-a-module","page":"Modules and Revise","title":"Create a module","text":"","category":"section"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"Create a file called, for example, MyModule.jl, in which you define a module of the same name. Include the files with your function definitions in this module:","category":"page"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"module MyModule\n    export f\n    include(\"./f.jl\")  \nend","category":"page"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"The export f command makes the f function visible from outside the module. That is, later when you load the module with using MyModule you will be able to directly call f(x) instead of having to type MyModule.f(1). Exporting or not functions is optional.","category":"page"},{"location":"modules/#Develop-using-Revise","page":"Modules and Revise","title":"Develop using Revise","text":"","category":"section"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"Now, start Julia and load the module with the following commands:","category":"page"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"using Revise\npush!(LOAD_PATH,\"/path/to/MyModule\")\nusing MyModule","category":"page"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"(it is a good idea to put these commands in a file, lets say devel.jl, to load it with julia -i devel.jl every time you start a development section). ","category":"page"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"This will load the module with its functions. Since the module was loaded after Revise, the changes to the files included in that module will be tracked and updated automatically. ","category":"page"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"That means that:","category":"page"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"julia> using Revise\n\njulia> push!(LOAD_PATH,\"/path/to/MyModule\")\n\njulia> using MyModule\n\njulia> f(1)\n2","category":"page"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"Now, if I modify the file f.jl such that the function multiplies the value of x by 5, and save it, we have:","category":"page"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"julia> f(1)\n5\n","category":"page"},{"location":"modules/","page":"Modules and Revise","title":"Modules and Revise","text":"Thus, the REPL section can be kept open and I can change and modify my package functions without having to load all the packages all the time.  The only situation, for now, that will require the restart of Julia is the redefinition of a struct, which for complicated reasons Revise is not able to track appropriately and update the state of the Julia section. ","category":"page"},{"location":"immutable/#Immutable-and-mutable-variables","page":"Mutability","title":"Immutable and mutable variables","text":"","category":"section"},{"location":"immutable/#Immutability-and-mutability","page":"Mutability","title":"Immutability and mutability","text":"","category":"section"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"In Julia there are mutable and immutable values (variables), and this distinction and implications are not always obvious depending on one's previous programming experience. ","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"For instance, having past experience with Fortran, this distinction was a novelty for me. In Fortran one declares every variable, and at the moment of declaring one has the impresion of having reserved a place in the memory for that variable, even with scalar one does that. Along the Fortran code, when a different value is assigned to the label assigned to the variable, the value changes, and that can be quite simply interpreted as if the value stored in the memory position which was reserved for that variable changed. ","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"From a Fortran user perspective, this result, for example, is quite astonishing:","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"julia> function add_one(x)\n           x = x + 1\n           return x\n       end;\n\njulia> x = 1\n1\n\njulia> add_one(x)\n2\n\njulia> x\n1","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"That codes appears to be mutating the value associated to the variable x but, nevertheless, the value of x is the outer scope does not change. ","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"In Julia (and many other higher-level languages, in particular), one has to understand the difference between mutable and imutable values. The reason, from a user perspective, derives from many features of high level languages. For instance, consider the code:","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"julia> x = 1\n1\n\njulia> x = [1, 2]\n2-element Vector{Int64}:\n 1\n 2","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"In a statically typed language, x would assume the value of an Int in the first assignment, and one would not be able to assign that label, x, to a different type of value, a vector of integers, in this case. The flexibility of a dynamic language requires labels, like x here, be only that, labels assigned to values. Then, one has to understand the properties of the values, in this case either the integer number 1 or the vector [1,2]. ","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"The number 1 is an immutable value. That is, we cannot convert it into something else. In some sense that's natural. What is less natural, then, a sequence of code like this:","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"x = 1\nx = 2","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"does not mean mutating the variable x, but simply assigning the label x to a different immutable value. ","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"The implications of this are important, as was shown in the add_one function above. From the structure of the function, one would be tempted to interpret that x was mutated inside it, and thus that the value of x after the application of the function would have changed. It does not, though, and this can be confusing. In this case, the point is that what was passed to the function was the value 1, an immutable value, and within add_one initially the label x was assigned to it. ","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"Next, in the line ","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"x = x + 1","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"the label x was reassigned, to the result of the value of the input x (1), plus one, and the value 2 was returned. The label x of the outer scope was simply unchanged, and continued to be assigned to the value 1. ","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"If we wanted to assign the label x of the outer scope of the function to the output of add_one, we would need to do that explicitly:","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"x = add_one(x)","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"Those considerations become initially more confusing when one sees the following code snippet:","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"julia> function add_one(x::Vector{Int})\n           x[1] = x[1] + 1 \n           return x\n       end;\n\njulia> x = [1,2]\n2-element Vector{Int64}:\n 1\n 2\n\njulia> add_one(x)\n2-element Vector{Int64}:\n 2\n 2\n\njulia> x\n2-element Vector{Int64}:\n 2\n 2","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"The most fundamental difference here is that x, as a Vector{Int}, that is, a vector of integers. That vector is mutable. That has an implication on how it is generally stored in the memory: it has an address. What is passed to the function is the address of the vector in memory. Inside add_one the vector is mutated, and the array is returned, meaning that its address in memory is returned. One can effectivelly assign a new label to the returned value:","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"julia> x = [1,2];\n\njulia> y = add_one(x);\n\njulia> y\n2-element Vector{Int64}:\n 2\n 2\n\njulia> x\n2-element Vector{Int64}:\n 2\n 2\n\njulia> y === x\ntrue","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"And the last line, comparing y and x with === confirms that these two labels are assigned to the exact same object.","category":"page"},{"location":"immutable/#Heap-and-Stack-memory","page":"Mutability","title":"Heap and Stack memory","text":"","category":"section"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"The distinction between mutable and mutable objects have important distinctions when it comes to performance. These distinctions are associated to the assumptions that the compiler can make about the behavior of these variables and, thus, about how they can be stored in the memory.","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"In particular, there are two major ways in which values (numbers, objects, arrays), can be stored in memory: in the heap or in the stack. Very roughly, the heap is the most flexible form of storing objects, and probably the one that maps more clearly into our naive intuitions about how memory works. In the heap the objects have addresses, which point to the actual positions in the memory where the objects are located. For example, ","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"x = [1,2]","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"is an array with that (normally) has an address in the heap memory, pointing to where the array starts. When we mutate one element of this array, we explicitly change the bit content at the physical memory position where the array is stored. This is fine, but it is slow, there are too many indirections in this process.","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"In the stack memory, the objects, and values, have a more loose sense. The stack, although physically the same, is a bunch of continuous memory reserved to be used by a program in an efficient manner. In particular, Fortran codes that do not use manual memory allocation will reserve all the memory required for the code in the stack. A continuous block of memory is reserved, and thus the accesses to the memory is fast, except that it brings some limitations in the use of the available computer memory (stack overflow errors are pretty common in old Fortran code).","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"The stack memory can be used very efficiently, in particular because the processor can directly access the values without the indirection associated to the address of those values. A function can write data to the stack memory quickly, at the end of the last used position (piling the data), use the memory, and finally just release the memory by informing the system the limits of that memory block used. In summary, this is fast, and as much as possible one would want that the stack model of memory is used for critical operations instead of heap memory. ","category":"page"},{"location":"immutable/#Relation-to-mutability-and-immutability","page":"Mutability","title":"Relation to mutability and immutability","text":"","category":"section"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"This properties of memory management become somewhat linked to the mutability and immutability of variables in Julia. This is not a strict relation (as we will see), but it is rule of thumb that is important in the design of fast Julia code: ","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"In general, new mutable values are stored in the heap, and new immutable values are stored in the stack. ","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"One reason for this behavior is that mutable values, in particular most arrays, can change in size. If they can change in size, significant memory rearrangements cannot be ruled out by the compiler, and thus the array storage starts with an address (a pointer), which can be adjusted if the content of the array has to be moved from one physical position in the memory to another position. For that the program has to request a memory space to the system, which takes time. This is all heap  memory flexibility in action.","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"On the other side, immutable values have a fixed memory size, and thus the compiler can reserve a block of memory for the value in the stack, use it, and release it when the lifetime of the object is over. Still more flexibility and optimizations are possible since the specific reserved block can be discarded in favor of a new stack allocation if that turns out to be the most efficient strategy for the specific set of operations in hand. ","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"For example, in our add_one function, slightly modified here for clarifying the argument:","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"function add_one(x::Int)\n    y = x + 1\n    return y\nend","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"there are two values involved. The immutable input value of x, and the also immutable value of y resulting from adding one to the input value.","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"Naively, one would could think that y requires a new position in memory, with a new address. Yet, this value of known bit size can be stored in the stack (in such a simple example the memory used can be even a processor cache, which is even faster), making the operation must faster than if we explicitly required a new memory place with an address bound. We can emulate requiring a new memory address for the y value with this code:","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"function add_one_allocate(x)\n    y = [ x + 1 ]\n    return y\nend","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"In this example, y will be returned as a Vector{Int}, with a single element equal to x + 1. Let us see how these functions perform:","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"julia> @btime add_one(1)\n  0.880 ns (0 allocations: 0 bytes)\n2\n\njulia> @btime add_one_allocate(1)\n  15.060 ns (1 allocation: 64 bytes)\n1-element Vector{Int64}:\n 2","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"Not only creating y in the second case \"counts\" as an allocation (because it is a heap allocation), but the code is much, much slower. This is \"correct\", and necessary here, since the compiler cannot know if y will be resized thereafter, such that it has to create a heap address to the object and request system memory for that. It cannot guarantee that y will fit the stack, which it can for immutable value resulting from the first function.  ","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"Thus, it is a general rule-of-thumb that working with immutable values is faster than with mutable ones, particularly in what concerns creating those values in intermediate computation states, where the values can be eventually discarded.","category":"page"},{"location":"immutable/#Static-arrays","page":"Mutability","title":"Static arrays","text":"","category":"section"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"The main property of immutable values is their fixed size. Thus, it is possible to perform fast computations with arrays if they are also fixed in size. The StaticArrays package brings this feature to Julia.","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"In many senses, a static array is no different from any other specific type of number, Int, Float64, for examples. Its representation in memory is a continuous block of memory of fixed size, except that it may contain more \"numbers\" (or other values). ","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"Static arrays allow programming patterns like this:","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"julia> function f()\n           s = 0.\n           for i in 1:1000\n               x = SVector{3,Float64}(i, sqrt(i), i^2)\n               for j in 1:3\n                   s = s + x[j]\n               end\n           end\n           s\n       end;\n\njulia> @btime f()\n  2.601 μs (0 allocations: 0 bytes)\n3.343550974558874e8","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"Wait, that function that generates 1000 vectors of dimension 3 does not allocate anything? Yet it doesn't, because these static arrays have fixed size, so they only exist in the fast memory positions which are temporary. Knowing this allows a bunch of code optimizations which are very cool, and a very pretty syntax if you are dealing with particle simulations. For instance, you can do:","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"julia> x = [ SVector{3,Float64}(1,1,1) for i in 1:3 ]; # positions of 3 particles\n\njulia> function update_positions!(x)\n           for i in eachindex(x)\n               y = 2*x[i] # whatever needed\n               x[i] = y \n           end\n       end;\n\njulia> update_positions!(x)\n\njulia> x\n10-element Array{SArray{Tuple{3},Float64,1,3},1}:\n [2.0, 2.0, 2.0]\n [2.0, 2.0, 2.0]\n [2.0, 2.0, 2.0]\n\njulia> @allocated update_positions!(x)\n0","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"Thus, even if we need to create temporary intermediate arrays, this can be done quickly, without heap allocations, and with a syntax that resembles the arithmetics of vectors very naturally. As an additional advantage, the function above functions just as well if the input x array is an array of scalars or static vectors of any other dimension. ","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"Since it is the fixed size that allows these optimizations, can't we have mutable arrays, with fixed size, that get also stack-allocated? In fact, we can, whenever the compiler can prove that no heap memory operation is required in the lifetime of the objects. Indeed, the StaticArrays package implements mutable arrays with static size, the MVectors, which can be used, for example, with this pattern:","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"julia> function update_positions!(x)\n           for i in eachindex(x)\n               y = MVector(x[i])\n               y[1] = 2.0\n               x[i] = SVector(y)\n           end\n       end;\n\njulia> x = [ SVector{3,Float64}(1,1,1) for i in 1:3 ]; # positions of 3 particles\n\njulia> update_positions!(x)\n\njulia> x\n3-element Vector{SVector{3, Float64}}:\n [2.0, 1.0, 1.0]\n [2.0, 1.0, 1.0]\n [2.0, 1.0, 1.0]\n\njulia> @btime update_positions!($x)\n  2.628 ns (0 allocations: 0 bytes)","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"What we did there is to copy the static arrays of x into a mutable static array of fixed size y, in y = MVector(x[i]). Next, we mutated the first component of y, and finally updated the value of x[i] with the mutated array, converted back to a static vector. The compiler could prove, there, that none of the mutable values escaped the scope of the function, and could optimize the code such that only stack memory used. This resulted in fast and non-allocating code.","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"The possibilities to improve the performance of a numerical code increase.","category":"page"},{"location":"immutable/#Immutable-structs","page":"Mutability","title":"Immutable structs","text":"","category":"section"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"There is nothing mysterious about StaticArrays. They are just convenient immutable structures, which you could have defined yourself, with the same allocation results:","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"julia> struct P\n           x::Float64\n           y::Float64\n           z::Float64\n       end\n\njulia> function update_positions!(x)\n           for i in eachindex(x)\n               y = P( 2*x[i].x, 2*x[i].y, 2*x[i].z )\n               x[i] = y   \n           end\n       end;\n\njulia> x = [ P(1.0,1.0,1.0) for i in 1:100 ];\n\njulia> update_positions!(x);\n\njulia> @allocated update_positions!(x)\n0","category":"page"},{"location":"immutable/","page":"Mutability","title":"Mutability","text":"Further information: Fortran compilers","category":"page"},{"location":"splitting/#Dealing-with-mixed-type-arrays","page":"Dealing with mixed-type arrays","title":"Dealing with mixed-type arrays","text":"","category":"section"},{"location":"splitting/","page":"Dealing with mixed-type arrays","title":"Dealing with mixed-type arrays","text":"To be explained.","category":"page"},{"location":"splitting/","page":"Dealing with mixed-type arrays","title":"Dealing with mixed-type arrays","text":"using BenchmarkTools\nabstract type Material end\n\nstruct Material1 <: Material\n  m :: Float64\nend\n\nstruct Material2 <: Material\n  m :: Float64\nend\n\nstruct HitPoint{T <: Material}\n  p :: Float64\n  r :: Float64\n  m :: T\nend\n\n#hit(p::HitPoint) = p.r*p.p*p.m.m\n\n# the key is to create specialized methods for every subtype:\nfor type in subtypes(Material)\n  eval(:(hit(p::HitPoint{$type}) = p.r*p.p*p.m.m))\n  eval(:((p::HitPoint{$type})() = p.r*p.p*p.m.m))\nend\n\nfunction hits_naive(hitpoints)\n  s = 0.\n  for p in hitpoints \n    s += hit(p)\n  end\n  s\nend\n\nfunction hits_splitting(hitpoints)\n  s = 0.\n  for p in hitpoints\n    if p isa HitPoint{Material1}\n      s += hit(p::HitPoint{Material1})\n    elseif p isa HitPoint{Material2}\n      s += hit(p::HitPoint{Material2})\n    end\n  end\n  s\nend\n\nfunction hits_functors(hitpoints)\n  s = 0.\n  for p in hitpoints \n    s += p()\n  end\n  s\nend\n\n\nusing BenchmarkTools\n\nn = 1000\nhitpoints = [ rand(Bool) ? HitPoint(rand(),rand(),Material1(rand())) : \n              HitPoint(rand(),rand(),Material2(rand())) for i in 1:n ]\n\nprintln(\" Mixed types: \")\nprint(\"naive:\");@btime hits_naive($hitpoints)\nprint(\"split:\");@btime hits_splitting($hitpoints)\nprint(\"funct:\");@btime hits_functors($hitpoints)\n\nhitpoints_single = HitPoint{Material1}[ HitPoint(rand(),rand(),Material1(rand())) for i in 1:n ]\n\nprintln(\" Single type: \")\nprint(\"naive:\");@btime hits_naive($hitpoints_single)\nprint(\"split:\");@btime hits_splitting($hitpoints_single)\nprint(\"funct:\");@btime hits_functors($hitpoints_single)\n","category":"page"},{"location":"splitting/","page":"Dealing with mixed-type arrays","title":"Dealing with mixed-type arrays","text":"Results:","category":"page"},{"location":"splitting/","page":"Dealing with mixed-type arrays","title":"Dealing with mixed-type arrays","text":"julia> include(\"./splitting2.jl\")\n Mixed types:\nnaive:  1.510 μs (0 allocations: 0 bytes)\nsplit:  2.975 μs (0 allocations: 0 bytes)\nfunct:  1.266 μs (0 allocations: 0 bytes)\n Single type:\nnaive:  992.167 ns (0 allocations: 0 bytes)\nsplit:  991.833 ns (0 allocations: 0 bytes)\nfunct:  991.833 ns (0 allocations: 0 bytes)\n117.02622654899025\n","category":"page"},{"location":"loadbalancing/#A-note-on-parallel-load-balancing","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"","category":"section"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"When running a parallel calculation, it is a good idea to divide the workload into chunks of known size. We have developed a simple package, ChunkSplitters.jl to perform such splitting. Here we make some considerations on why it should be used and how to cope with highly uneven parallel workloads. ","category":"page"},{"location":"loadbalancing/#Using-@threads-and-@spawn","page":"A note on parallel load balancing","title":"Using @threads and @spawn","text":"","category":"section"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"To simulate a highly uneven workload, first we create a function that occupies a processor for a known amount of time given an input. Like a sleep function, but that actually does some work and doesn't let the processor free:","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"julia> function work_for(;time=1, cycles_for_one_second=4*10^7)\n           x = 0.0\n           for i in 1:time*cycles_for_one_second\n               x += abs(sin(log(i)))\n           end\n           return x\n       end\n\njulia> @time work_for(time=0.5)\n  0.507590 seconds\n1.1355518913947988e7","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"with that number of cycles the function takes roughly 1 second in my laptop if time == 1. By changing the input time we can now create very uneven workloads in a parallel run.","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"For example, let us sum N = 120 random numbers but introducing the call to work_for at each iteration, with a time proportional to the index of the iteration (time = i*dt):","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"julia> using BenchmarkTools \n\njulia> function sum_N(;N=120, dt=0.001)\n           s = 0\n           for i in 1:N\n               work_for(time=i*dt)\n               s += rand()\n           end\n           return s\n       end\n\njulia> @btime sum_N()\n  8.144 s (0 allocations: 0 bytes)\n68.66902947218264","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"The function takes about 8 seconds. It is slow, and we want to parallelize it. However, the workload is very uneven, as the work_for call for i == 1 takes 0.001 s, and for i == 120 it takes 0.12 s. ","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"We will now write a parallel version of this sum, using the Julia Base @threads macro. We have initialized julia with julia -t 12, such that 12 threads are available. We will also count the number of tasks executed by each thread, accumulated in the n array:","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"julia> using Base.Threads \n\njulia> function sum_N_threads(;N=120, dt=0.001)\n           s = zeros(nthreads())\n           n = zeros(Int, nthreads())\n           @threads for i in 1:N\n               work_for(time=i*dt)\n               s[threadid()] += rand()\n               n[threadid()] += 1\n           end\n           return sum(s), n\n       end\n\njulia> @btime sum_N_threads()\n  1.422 s (80 allocations: 7.47 KiB)\n(50.43661472139146, [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10])","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"The function is about 7-8 times faster, with 12 threads. Note, also, that each thread as responsible for exactly 10 tasks, and this is not optimal given the uneven workload involved.","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"note: Note\nWe have used threadid() here, which is not a recommended pattern, because in  some situations thread migration can cause concurrency problems. In fact, this is main reason for the existence of ChunkSplitters.jl, but here we will  discuss the additional gains associated with a finer control of the parallelization.","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"Let us try to use @spawn instead:","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"julia> function sum_N_spawn(;N=120, dt=0.001)\n           s = zeros(nthreads())\n           n = zeros(Int, nthreads())\n           @sync for i in 1:N\n               @spawn begin\n                   work_for(time=i*dt)\n                   s[threadid()] += rand() \n                   n[threadid()] += 1 \n               end\n           end\n           return sum(s), n\n       end\n\njulia> @btime sum_N_spawn()\n  961.869 ms (628 allocations: 64.86 KiB)\n(62.64823839506871, [11, 11, 9, 9, 10, 9, 12, 10, 10, 10, 8, 11])","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"So @spawn did a better job, because while @threads assigns the workload to each thread in advance, @spawn does not, and will use the available threads as they become free. ","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"Nevertheless, @spawn has launched a different task for each workload, and that is reflected in the greater number of allocations it involved. We can see this more clearly if the number of tasks is much greater (N=100*120, but we reduce dt to keep reasonable running times):","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"With @threads:","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"julia> @btime sum_N_threads(N=120*10^2, dt=1e-7)\n  1.389 s (75 allocations: 7.31 KiB)\n(5945.862883176399, [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000])","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"and now with @spawn: ","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"julia> @btime sum_N_spawn(N=100*120, dt=1e-7)\n  911.976 ms (65901 allocations: 6.45 MiB)\n(6010.25758204897, [996, 942, 1023, 1019, 984, 1027, 989, 995, 989, 1016, 994, 1026])","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"The @spawn strategy still gains in execution time, but we note that the memory allocated by it increased significantly, which can be an issue for the parallelization of large collections. On the other side, @threads allocates only a minimal set of auxiliary buffers.","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"Can we have the best of both worlds?","category":"page"},{"location":"loadbalancing/#Using-ChunkSplitters","page":"A note on parallel load balancing","title":"Using ChunkSplitters","text":"","category":"section"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"ChunkSplitters provides an additional control over the chunking of the tasks, and can be used with @threads or @spawn as the underlying parallel protocol.","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"The function above will be implemented initially with @threads as:","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"julia> using ChunkSplitters\n\njulia> function sum_N_chunks(;N=120, dt=0.001, nchunks=nthreads(), chunk_type=:batch)\n           s = zeros(nchunks)\n           n = zeros(Int, nchunks)\n           @threads for (i_range, i_chunk) in chunks(1:N, nchunks, chunk_type)\n               for i in i_range\n                   work_for(time=i*dt)\n                   s[i_chunk] += rand()\n                   n[i_chunk] += 1\n               end\n           end\n           return sum(s), n\n       end","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"We can now choose the number of chunks in which the workload is divided (by default nchunks=nthreads()), and each chunk will be assigned to one thread. A range of indexes of the collection 1:N will be stored in i_range and associated with the chunk i_chunk. We get rid, with this, of the use of threadid(), which is nice, because thread migration cannot affect our result anymore.","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"We initially use the :batch chunking type, which will just divide the workload consecutively. This will be similar to what @threads does, and since there is a correlation between index and cost of the task, this is not optimal:","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"julia> @btime sum_N_chunks(N=100*120, dt=1e-7)\n  1.463 s (77 allocations: 7.56 KiB)\n(6035.277380219111, [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000])","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"We have, now the option to create chunks scattered through the workload, and that can be effective to distribute the workload better given the known correlation of index and cost:","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"julia> @btime sum_N_chunks(N=100*120, dt=1e-7, chunk_type=:scatter)\n  898.642 ms (77 allocations: 7.56 KiB)\n(6073.279878329541, [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000])","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"Note that, in this specific case, the :scatter chunking is optimal, because it will assign the tasks in an alternating fashion to the threads. Associated with the small allocation cost, the result can be faster than @spawning the tasks on demand. ","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"We can also use @spawn with ChunkSplitters, with:","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"julia> function sum_N_chunks(;N=120, dt=0.001, nchunks=nthreads(), chunk_type=:batch)\n           s = zeros(nchunks)\n           n = zeros(Int, nchunks)\n           @sync for (i_range, i_chunk) in chunks(1:N, nchunks, chunk_type)\n               @spawn for i in i_range\n                   work_for(time=i*dt)\n                   s[i_chunk] += rand()\n                   n[i_chunk] += 1\n               end\n           end\n           return sum(s), n\n       end","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"Which gives us with the :batch chunking mode a suboptimal performance, because the workload is divided by thread in advance:","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"julia> @btime sum_N_chunks(N=100*120, dt=1e-7, chunk_type=:batch)\n  1.457 s (117 allocations: 8.66 KiB)\n(5974.13618602343, [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000])","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"We can, nevertheless, use a different strategy here, which is to increase the number of chunks, thus reducing the individual cost of each task. The number of spawned tasks can now be controlled by the nchunks parameter:","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"julia> @btime sum_N_chunks(N=100*120, dt=1e-7, nchunks=144, chunk_type=:batch)\n  907.016 ms (1037 allocations: 88.39 KiB)\n(5993.798439269024, [84, 84, 84, 84, 84, 84, 84, 84, 84, 84  …  83, 83, 83, 83, 83, 83, 83, 83, 83, 83])","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"Here we are in the middle ground between a simple @spawn strategy which launches a different task for each calculation, and a @thread strategy which launches nthreads() tasks. Yet, note that the memory allocated is much less than with the simple use of @spawn. ","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"We can, of course, use the :scatter chunking here as well:","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"julia> @btime sum_N_chunks(N=100*120, dt=1e-7, chunk_type=:scatter)\n  958.821 ms (112 allocations: 8.50 KiB)\n(5981.069201763822, [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000])","category":"page"},{"location":"loadbalancing/","page":"A note on parallel load balancing","title":"A note on parallel load balancing","text":"which, compared to the :batch chunking, is faster, but it does not perform necessarily better in this example than the combination of :scatter and @threads, because here this choice promotes the ideal load balancing. ","category":"page"},{"location":"fastrepl/#Cool-and-fast-loading-REPL","page":"Cool and fast REPL","title":"Cool and fast loading REPL","text":"","category":"section"},{"location":"fastrepl/","page":"Cool and fast REPL","title":"Cool and fast REPL","text":"This was a suggestion from Michael Fiano in a Zulip chat. It makes the startup really fast, and with a nice setup for OhMyREPL. Install the packages first:","category":"page"},{"location":"fastrepl/","page":"Cool and fast REPL","title":"Cool and fast REPL","text":"julia> import Pkg\n\njulia> Pkg.add(\"Revise\", \"OhMyREPL\", \"Crayons\", \"BenchmarkTools\")","category":"page"},{"location":"fastrepl/","page":"Cool and fast REPL","title":"Cool and fast REPL","text":"And add the following to the ~/.julia/config/startup.jl:","category":"page"},{"location":"fastrepl/","page":"Cool and fast REPL","title":"Cool and fast REPL","text":"Base.atreplinit() do repl\n    @eval begin\n        @async @eval using Revise\n        @async @eval using BenchmarkTools\n        import OhMyREPL as OMR\n        import Crayons as C\n        promptfn() = \"(\" * splitpath(Base.active_project())[end-1] * \") julia> \"\n        OMR.input_prompt!(promptfn)\n        OMR.colorscheme!(\"OneDark\")\n        OMR.enable_pass!(\"RainbowBrackets\", false)\n        OMR.Passes.BracketHighlighter.setcrayon!(C.Crayon(foreground=:blue))\n    end\nend","category":"page"},{"location":"fastrepl/","page":"Cool and fast REPL","title":"Cool and fast REPL","text":"From this thread (probably the link will be broken).","category":"page"},{"location":"memory/#Tracking-memory-allocations","page":"Tracking allocations","title":"Tracking memory allocations","text":"","category":"section"},{"location":"memory/#Manually","page":"Tracking allocations","title":"Manually","text":"","category":"section"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"A quick way to test allocations is to use the @allocated macro, which  is available in Base Julia. For example:","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"a = @allocated begin\n    Block to test\nend; a > 0 && @show a","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"That will print something if the code block allocated something.","category":"page"},{"location":"memory/#Using-TimerOutputs","page":"Tracking allocations","title":"Using TimerOutputs","text":"","category":"section"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"One practical tool is TimerOutputs. Install it as usual, and use it with, for example:","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"using TimerOutputs\nconst tmr = TimerOutput();","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"In the code, flag the code lines or blocks with the @timeit macro. For example:","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"struct A\n  x\nend\nfunction test(n,x)\n    @timeit tmr \"set y\" y = Vector{A}(undef,n)\n    @timeit tmr \"loop\" for i in 1:n\n        @timeit tmr \"assign y\" y[i] = A(i*x)\n    end\n    y\nend","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"Running this function fills the tmr object with the time and allocation results:","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"julia> test(10,rand());\n\njulia> tmr\n ─────────────────────────────────────────────────────────────────────\n                              Time                   Allocations      \n                      ──────────────────────   ───────────────────────\n   Tot / % measured:        176s / 0.00%            103MiB / 0.00%    \n\n Section      ncalls     time   %tot     avg     alloc   %tot      avg\n ─────────────────────────────────────────────────────────────────────\n loop              2   8.34μs  72.6%  4.17μs   1.14KiB  78.5%     584B\n   assign y       20   3.18μs  27.7%   159ns      320B  21.5%    16.0B\n set y             2   3.15μs  27.4%  1.58μs      320B  21.5%     160B\n ─────────────────────────────────────────────────────────────────────","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"However, @timeit causes some allocations on its own. Therefore, nested calls can cause confusion. This can be verified in the example above. Removing the \"assign y\" check inside the loop results in:","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":" ──────────────────────────────────────────────────────────────────\n                           Time                   Allocations      \n                   ──────────────────────   ───────────────────────\n Tot / % measured:      9.74s / 0.00%           6.00MiB / 0.01%    \n\n Section   ncalls     time   %tot     avg     alloc   %tot      avg\n ──────────────────────────────────────────────────────────────────\n set y          1   1.29μs  80.6%  1.29μs      160B  50.0%     160B\n loop           1    311ns  19.4%   311ns      160B  50.0%     160B\n ──────────────────────────────────────────────────────────────────","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"Note that now the loop allocates less. Also, this result is consistent now with the Profile result shown below.","category":"page"},{"location":"memory/#Using-the-Profiler","page":"Tracking allocations","title":"Using the Profiler","text":"","category":"section"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"To track allocations along the complete code, it is possible to use a profiler, although this generates so much information that it is somewhat confusing. Sometimes the output is not clear either, perhaps even wrong. ","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"For example, consider this is the code (file name here: test.jl):","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"struct A\n    x\nend\n\nfunction test(n,x)\n    y = Vector{A}(undef,n)\n    for i in 1:n\n        y[i] = A(i*x)\n    end\n    y\nend","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"Run julia with:","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"julia --track-allocation=user","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"Within Julia, do:","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"julia> using Profile\n\njulia> include(\"./test.jl\")\ntest (generic function with 1 method)\n\njulia> test(10,rand()); # gets compiled\n\njulia> Profile.clear_malloc_data() # clear allocations\n\njulia> test(10,rand());","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"Exit Julia, this will generate a file test.jl.XXX.mem (extension .mem), which, in this case, contains:","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"        - struct A\n        -     x\n        - end\n        -\n        - function test(n,x)\n      160     y = Vector{A}(undef,n)\n        0     for i in 1:n\n      160       y[i] = A(i*x)\n        -     end\n        0     y\n        - end\n","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"Where the lines with non-zero numbers are the lines where allocations occur.","category":"page"},{"location":"memory/","page":"Tracking allocations","title":"Tracking allocations","text":"More information: Disabling allocations","category":"page"},{"location":"workflow/#Nice-workflows-for-using-and-developing-Julia-1.9","page":"Development workflow","title":"Nice workflows for using and developing Julia 1.9+","text":"","category":"section"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"This a brief description of some nice development workflows for Julia, particularly for versions 1.9 or greater. This workflows are usually fairly personal, so many other useful ones may exist. ","category":"page"},{"location":"workflow/#juliaup","page":"Development workflow","title":"juliaup","text":"","category":"section"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"The juliaup tool allows an easy handling of Julia installations and versioning. In short, if you are using Linux, install juliaup with:","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"curl -fsSL https://install.julialang.org | sh","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"then, close the terminal, start it again. The juliaup and julia executables will be available in your path. By default, juliaup installs the latest stable version of Julia, which as of the writing of this text was 1.8.5. We want to work with the upcoming 1.9 series, so we start by installing it:","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"juliaup add 1.9","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"which will currently install, as of today, the 1.9.0-rc1 version of Julia. Then, lets make it the default Julia:","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"juliaup default 1.9","category":"page"},{"location":"workflow/#Revise-and-startup.jl","page":"Development workflow","title":"Revise and startup.jl","text":"","category":"section"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"Revise.jl is a fundamental tool for Julia development and use. It allows one to track changes to files and, thus, to very effectively develop new functions, tune plots, etc, by editing an script in parallel to an active Julia section. Thus, add revise to your main environment:","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"julia> ] add Revise","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"(remembering that the ] will take you to the package manager prompt: (@v1.9) pkg>).","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"Next, let us guarantee that Revise is always loaded on startup. Add it to (or create the file) ","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"~/.julia/config/startup.jl","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"and to it the line","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"using Revise","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"which will make Revise to be loaded on each Julia startup. ","category":"page"},{"location":"workflow/#Why-Revise","page":"Development workflow","title":"Why Revise","text":"","category":"section"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"With Revise loaded, it is possible to edit/develop scripts simply modifying the script and re-running functions in an open Julia section. For example, given the script that  generates some data and then plots it:","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"using Plots\nfunction my_data(n)\n    data = randn(n)\n    return data\nend\nfunction my_plot(data)\n    plt = plot(data; label=\"My data\"; linewidth=1)\n    return plt\nend","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"If we save the script in a myplot.jl file, and within Julia, we includet (note the t! - for \"track\"):","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"julia> includet(\"./myplot.jl\")\n\njulia> data = my_data(1000);\n\njulia> my_plot(data)","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"we generate the plot. Then, without leaving the Julia REPL, we can change any property of the data or the plot in the script, save the file, and re-run the functions changed, and they will reflect automatically the updates to the file. ","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"The video below illustrates such a feature, by changing the line width of the plot, and executing again the my_plot function. ","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"<center>\n<iframe width=\"733\" style=\"height:400px\" src=\"https://www.youtube.com/embed/GeldXJ-cgHM\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</center>","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"note: Note\nThe video illustrates the use of Revise from within VSCode, which is also a recommended tool for an effective workflow, but is not required here nor will be discussed in this text. In any case, if you are using it, install the Julia extension.","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"note: Note\nThe example above illustrates some advantages of splitting Julia code into functions. With that layout, the function my_plot can be repeatedly executed at the REPL, tracking the changes made on the file. The same could be done with the data-generation function, for example, if the data has to be reloaded from different files, for example. Note, additionally, that it is good to structure Julia code in functions for performance reasons (functions get compiled to efficient native code), although in this example that is a essentially irrelevant. ","category":"page"},{"location":"workflow/#Environments","page":"Development workflow","title":"Environments","text":"","category":"section"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"Julia 1.9 makes it particularly appealing to use environments for specific tasks, because the compiled code of the libraries gets stored in a environment-specific manner, making the load times of the libraries quicker than in previous Julia versions. Besides, the use of environments allows one to obtain completely reproducible setups. Let us take the previous script,  but we will load another large package DataFrames, and use it to store the sample data we are creating:","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"using Plots\nusing DataFrames\nfunction my_data(n)\n    data = DataFrame(:x => randn(n))\n    return data\nend\nfunction my_plot(data)\n    plt = plot(data.x; label=\"My data\", linewidth=1)\n    return plt\nend","category":"page"},{"location":"workflow/#Creating-and-installing-packages","page":"Development workflow","title":"Creating and installing packages","text":"","category":"section"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"Since Plots and DataFrames are relatively heavy packages, they take a while to install and compile. We will do that within an new environment. First, create a directory that will contain the environment files. We choose to save the environments within a ~/.JuliaEnvironments directory, but that is completely optional, environments are stored in regular directories:","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"mkdir ~/.JuliaEnvironments \nmkdir ~/.JuliaEnvironments/mydataplots","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"The mydataplots is the directory where the environment files will be automatically created. ","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"Then, start Julia and ","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"julia> ] # go to pkg prompt\n\n(@v1.9) pkg> activate ~/.JuliaEnvironments/mydataplots\n  Activating new project at `~/.JuliaEnvironments/mydataplots`\n\n(mydataplots) pkg>","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"and note that the pkg> prompt reflects that the mydataplots environment is activated. We now add the necessary packages, which can take some minutes, depending on the internet connection and speed of the computer:","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"(mydataplots) pkg> add Plots, DataFrames\n   Resolving package versions...\n   ...","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"after the installation is finished, let us simulate the use of the packages for the first time, which may trigger additional compilation. Type backspace to go back to the Julia prompt, and do:","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"julia> using Plots, DataFrames\n[ Info: Precompiling Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80]\n[ Info: Precompiling DataFrames [a93c6f00-e57d-5684-b7b6-d8193f3e46c0]\n","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"which may also take some time (it is well possible that the packages don't get precompiled again, on this first using, but sometimes they are because of dependency version updates).","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"That's all for the installation part.","category":"page"},{"location":"workflow/#Using-the-environment","page":"Development workflow","title":"Using the environment","text":"","category":"section"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"You can quit Julia, and let us move to the directory of the working script:","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"cd ~/Documents/mytestscript","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"Here we have the script.jl containing the code shown above, using Plots and DataFrames, as example packages.  ","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"Now start Julia, and activate the mydataplots environment, with:","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"julia> ] # go to pkg prompt\n\n(@v1.9) pkg> activate /home/user/.JuliaEnvironments/mydataplots/\n  Activating project at `~/.JuliaEnvironments/mydataplots`\n\n(mydataplots) pkg>","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"type backspace go back to the Julia prompt, and include the script (here with includet, assuming that Revise is loaded by default):","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"julia> includet(\"./myscript.jl\")","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"This should take now a couple of seconds. And the responsiveness of the function should be good:","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"julia> @time data = my_data(1000)\n  0.002078 seconds (33 allocations: 18.031 KiB, 94.87% compilation time)\n1000×1 DataFrame\n  Row │ x          \n      │ Float64    \n──────┼────────────\n    1 │ -2.41804\n    2 │ -0.51387\n    3 │  0.953752\n    4 │  0.738998\n    5 │  0.973528\n  ⋮   │     ⋮\n  997 │  0.707327\n  998 │  0.200788\n  999 │ -0.84872\n 1000 │ -1.49911\n   991 rows omitted","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"and","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"julia> @time my_plot(data)\n  0.635311 seconds (2.83 M allocations: 172.703 MiB, 9.92% gc time, 99.49% compilation time: 72% of which was recompilation)","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"Thus, in a few seconds, the script can be completely run, avoiding usual delays of recompilation of the packages involved, which happened often in previous versions of Julia.","category":"page"},{"location":"workflow/#Automatic-activation","page":"Development workflow","title":"Automatic activation","text":"","category":"section"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"Now, let us automate the activation of the environment, by adding to the top of the script the following first line:","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"import Pkg; Pkg.activate(\"/home/user/.JuliaEnvironments/mydataplots\") # added line\nusing Plots\n... # script continues","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"Now, when including the script, it will automatically activate that environment, and use the packages installed for it. It is even possible to just execute the script from the command-line with an acceptable performance. The script, shown below, now contains the execution of the functions and saving the plot to a figure:","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"user@m3g:~/Documents/mytestscript% time julia myscript.jl \n  Activating project at `~/.JuliaEnvironments/mydataplots`\n\nreal\t0m5,172s\n...","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"The complete script is:","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"import Pkg; Pkg.activate(\"/home/user/.JuliaEnvironments/mydataplots\")\nusing Plots\nusing DataFrames\nfunction my_data(n)\n    data = DataFrame(:x => randn(n))\n    return data\nend\nfunction my_plot(data)\n    plt = plot(data.x; label=\"My data\", linewidth=1)\n    return plt\nend\ndata = my_data(1000)\nplt = my_plot(data)\nsavefig(plt,\"plot.png\")","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"Of course, you can use the same environment for all scripts that require the same set of packages, with the same benefits. ","category":"page"},{"location":"workflow/","page":"Development workflow","title":"Development workflow","text":"note: Note\nIt is not impossible that you get some recompilation of the packages from time to time if, in particular, new packages are loaded in the same environment. However, once the packages of the environment are stable, precompilation should only occur when trying to use the same environment in different version of Julia.","category":"page"},{"location":"typevariance/#Vector{Int}-:-Vector{Real}-is-false??","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false??","text":"","category":"section"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"Covariance and etc. mean so many things outside computer science that it took me a while to get what people meant when explaining covariance, contravariance, invariance, etc, in the context of Julia type system.","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"I prefer to explain the relation between the container types, probably not as comprehensively, but at least simply, by noting that:","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"First, we have to differentiate two things:","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"a) An array that can only contain numbers of type Float64","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"b) An array that can contain real numbers of different types (mixed Float64 and Int64, for example).","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"Vectors of type (b) are not a subtype of vectors of type (a), of course, because vectors of type (a) cannot contain an Int64, for example. This is clear and translates to:","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"Vector{Real} <: Vector{Float64} == false","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"Less clear is that an array of type (a) is also not a subtype of an array of type (b). This is because an array of type (a) has one constraint that vectors of type (b) do not. Thus, a vector of type (a) is not a subtype of vectors of type (a), and this translates to the more unnatural","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"Vector{Float64} <: Vector{Real} == false","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"Second, the usual confusion is that Vector{Real} is intuitively thought as all types of vectors that contain real numbers. Well, this is the wrong way of reading that. As pointed above, Vector{Real} is the type of a concrete vector that is able to contain any type of real number. Thus, this does not include the vectors that cannot  contain Int64s, for instance. ","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"We need a notation for the set of vectors that may contain real numbers, restricted or not by type. The notation might sound arbitrary, but we need one, and it is Vector{<:Real}. Since this is the notation that encompasses different types of vectors, it is an abstract type**, contrary to the other two above, which are *concrete types.","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"No actual vector is, therefore, of type Vector{<:Real}. To be very redundant:","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"julia> typeof(Real[1,2.0,π,Float32(7)]) == Vector{<:Real}\nfalse","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"But all vectors  that contain only real numbers, are subtypes of Vector{<:Real}:","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"julia> typeof(Real[1,2.0,π,Float32(7)]) <: Vector{<:Real}\ntrue\n\njulia> typeof(Int[1,2,3]) <: Vector{<:Real}\ntrue","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"When one uses Vector{<:Real} we are referring a set of types. The final confusion that may arise, is, for example, that:","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"julia> typeof(Int64[1,2,3]) == Vector{<:Int64}\nfalse","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"This is false because Vector{<:Int64} is the set of types of vectors that contain only Int64 numbers. It is not a concrete type of vector, even if the set contains only one type which is Vector{Int64}. ","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"Of course:","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"julia> typeof(Int64[1,2,3]) <: Vector{<:Int64}\ntrue","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"A final note: checking if a concrete type is a concrete type or a subtype of a supertype that contains it can be done with isa:","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"julia> Int[1,2,3] isa Vector{Int}\ntrue\n\njulia> Int[1,2,3] isa Vector{Real}\nfalse\n\njulia> Int[1,2,3] isa Vector{<:Real}\ntrue\n","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"Note that isa corresponds to typeof(x) <: T, not typeof(x) == T. This makes sense because then 1 isa Number, for example, while typeof(1) == Number is false, because Number is an abstract type.","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"*Strictly speaking, in the Julia language, something like Vector{<:Real}  is of the UnionAll type, which is something in between between a completely abstract type which only serve as nodes in the type tree, and a concrete type which can actually be instantiated. UnionAll types do have information on how they should be instantiated, but that information is not complete.","category":"page"},{"location":"typevariance/","page":"Vector{Int} <: Vector{Real} is false???","title":"Vector{Int} <: Vector{Real} is false???","text":"Note: This text was originally posted as a response to this thread, and its final form includes contributions from other people, as indicated in the thread.","category":"page"},{"location":"anonymous/#Anonymous-functions-and-closures","page":"Anonymous functions","title":"Anonymous functions and closures","text":"","category":"section"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"Anonymous functions and closures are an important part of the Julia syntax.","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"For example, a simple example of the frequent use of anonymous functions is on calls to the findfirst function, which returns the element of an array which first matches a condition:","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"julia> x = [ 0, π/4, π/2, π ]\n4-element Array{Float64,1}:\n 0.0\n 0.7853981633974483\n 1.5707963267948966\n 3.141592653589793\n\njulia> findfirst( x -> sin(x) > 0.5, x )\n2","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"The x -> sin(x) > 0.5 is an anonymous function, which one can read as \"given x return sin(x) > 0.5\", which in this case can be true or false. ","category":"page"},{"location":"anonymous/#Basic-syntax-and-closures","page":"Anonymous functions","title":"Basic syntax and closures","text":"","category":"section"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"Consider the following function:","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"a = 5\nf(x,a) = a*x","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"This function is also a \"closure\", because it \"closes over\" the variable a. Be careful, if written in global scope, this a is type-unstable, unless if declared const.","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"We can define an anonymous function which, given x, returns the result of f(x,a):","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"x -> f(x,a) ","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"The anonymous function can be bound to a label name, as any other value:","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"g = x -> f(x,a)","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"and g will be a function that, given x, returns f(x,a). This definition is similar to","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"g(x) = f(x,a)","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"Except that in the latter case the label g is bound to the function in definitive:","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"julia> g(x) = f(x,a)\ng (generic function with 1 method)\n\njulia> g = 2\nERROR: invalid redefinition of constant g","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"While in the former case g can be redefined at will, as it is only a label bound to the address of an anonymous function:","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"julia> g = x -> f(x,a)\n#1 (generic function with 1 method)\n\njulia> g = 2\n2","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"Anonymous functions for functions with multiple parameters, and closing over multiple values can be defined likewise:","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"(x,y) -> f(x,y,a,b,c)","category":"page"},{"location":"anonymous/#Use-case","page":"Anonymous functions","title":"Use case","text":"","category":"section"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"As exemplified for the findfirst function, the most important use for anonymous functions is passing functions as arguments to other functions, in particular when the function needs additional data to be evaluated.  Consider the following toy example which reproduces a common scenario in which anonymous functions appear:","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"Let us suppose we have a package which implements a solver for an optimization problem. That is, the solver receives a function and an initial point, and returns the minimizer of that function. A typical call for such a solver would be","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"x = solver(f,x0)","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"where f is the function to be minimized and x0 the initial guess.  Within the solver code you will find calls to f of the form f(x).","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"If f is a function like f(x) = x^2 + 2x - 3, we can just define the function and call the solver with f.  ","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"However, what if f depends on data? For example, if f was defined as:","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"f(x,a,b,c) = a*x^2 + b*x + c","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"The solver does not explicitly support calls to f with general arguments, because that would be cumbersome. How can we then call the solver with a function which will be interpreted by the solver as f(x) but uses the parameters a, b, and c? That is what the anonymous functions solve here.","category":"page"},{"location":"anonymous/#Example","page":"Anonymous functions","title":"Example","text":"","category":"section"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"For example, lets create a \"solver\" that only evaluates the function f and returns:","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"julia> function solver(f,x)\n          y = f(x)\n          return y\n       end\nsolver (generic function with 1 method)","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"Then, let us define a function that depends on three constant parameters besides that the variable x:","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"julia> const a, b, c = 1, 2, 3; \n\njulia> g(x) = a*x^2 + b*x + c","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"We can do, now:","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"julia> x = 5.;\n\njulia> solver(g,x)\n38.0","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"Alternatively, one could use an anonymous function:","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"julia> solver(x -> a*x^2 + b*x + c,x)\n38.0","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"We could, also, use g = x -> a*x^2 + b*x + c, but this option will be less preferred as it is just a wacky way to write g(x) = a*x^2 + b*x +c.  ","category":"page"},{"location":"anonymous/#Scope-of-variables","page":"Anonymous functions","title":"Scope of variables","text":"","category":"section"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"In the examples of the previous section, the parameters a, b, and c of the function g were defined in the global scope will cause type-instability problems. In the definition of the function as ","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"g(x) = a*x^2 + b*x + c","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"it is quite evident, as g does not receive the parameters as arguments (the purpose of the definition of g was that one) and thus g is using those parameters from the global scope.","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"Using the anonymous functions the scope of the parameters is the same, even if this is less evident. In","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"solver(x -> a*x^2 + b*x + c, x) ","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"the anonymous function x -> a*x^2 + b*x + c was parsed at the calling scope, not at the scope of the solver. Therefore, except for not having a name, it behaves exactly as the former g(x), thus the parameters are non-constant globals and will introduce type instabilities and performance penalties.  ","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"The parameters of the anonymous function have to be, therefore, constant for the code to be type-stable and performant. This is why we declared them as constants,","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"julia> const a, b, c = 1, 2, 3;","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"Alternatively (and better, because it is more flexible), we can wrap the call to the solver in a function that receives the data as parameters, in which case the scope of the data will be the scope of the calling function of the solver, not the global scope:","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"julia> a, b, c = 1, 2, 3; # not necessarily constant\n\njulia> function h(x,a,b,c) \n           return solver(x -> a*x^2 + b*x + c,x)\n       end\nh (generic function with 1 method)\n\njulia> x = 5.0;\n\njulia> h(x,a,b,c)\n38.0\n","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"(one could have written h(x,a,b,c) = solver(x->a*x^2 + b*x + c,x), but the syntax above is more explicit in the fact that h has its own scope of variables). ","category":"page"},{"location":"anonymous/#Take-away","page":"Anonymous functions","title":"Take away","text":"","category":"section"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"Passing functions as argument to other functions, in particular if the evaluation of data is required, is practical with the use of anonymous functions and closures.  This occurs very frequently in the context of calls to solvers, but very frequently also in the Julia base language, for example in the search and sorting, functions, among many others. One has to keep in mind that the closures are parsed at the calling scope, such that critical code for performance must always be wrapped into functions, to guarantee the constant types of the parameters. Let us just reinforce this point with an example.","category":"page"},{"location":"anonymous/#Example-of-type-instability","page":"Anonymous functions","title":"Example of type-instability","text":"","category":"section"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"Let us write a function that operates on a vector, returning a some \"potential energy\" associated to some computation on pair of elements of the vector:","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"julia> function u(f,x)\n         u = 0.\n         for i in 1:length(x)-1\n            for j in i+1:length(x)\n              u += f(x[i],x[j])\n            end\n         end\n         u\n       end\nu (generic function with 1 method)\n","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"Let use define f as ","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"julia> f(x,y,a,b) = a*x - b*y\nf (generic function with 1 method)\n","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"And we will use an anonymous function to pass the function f to u: ","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"julia> a = 5; b = 7;\n\njulia> u( (x,y) -> f(x,y,a,b), x )\n-567899.3283195692\n","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"An analysis of the stability of the types will indicate type-instabilities, associated with the global scope of the parameters a and b: ","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"julia> @code_warntype u( (x,y) -> f(x,y,a,b), x )\nVariables\n  #self#::Core.Compiler.Const(u, false)\n...\n  x::Array{Float64,1}\n  u::Any\n  @_5::Union{Nothing, Tuple{Int64,Int64}}\n...\nBody::Any\n1 ─       (u = 0.0)\n...\n│   %22 = u::Any\n│   %23 = Base.getindex(x, i)::Float64\n│   %24 = Base.getindex(x, j)::Float64\n│   %25 = (f)(%23, %24)::Any\n│         (u = %22 + %25)\n...\n","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"If, alternatively, one defines an enclosing function for the call to the energy function,","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"julia> h(x,a,b) =  u( (x,y) -> f(x,y,a,b), x )\nh (generic function with 1 method)\n","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"The type-instabilities are resolved, because the scope in which the anonymous functions is parsed is now the local scope of h and, thus, all variables have constant types:  ","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"julia> @code_warntype h(x,a,b)\nVariables\n  #self#::Core.Compiler.Const(h, false)\n  x::Array{Float64,1}\n  a::Int64\n  b::Int64\n  #18::var\"#18#19\"{Int64,Int64}\n\nBody::Float64\n1 ─ %1 = Main.:(var\"#18#19\")::Core.Compiler.Const(var\"#18#19\", false)\n│   %2 = Core.typeof(a)::Core.Compiler.Const(Int64, false)\n│   %3 = Core.typeof(b)::Core.Compiler.Const(Int64, false)\n│   %4 = Core.apply_type(%1, %2, %3)::Core.Compiler.Const(var\"#18#19\"{Int64,Int64}, false)\n│        (#18 = %new(%4, a, b))\n│   %6 = #18::var\"#18#19\"{Int64,Int64}\n│   %7 = Main.u(%6, x)::Float64\n└──      return %7\n","category":"page"},{"location":"anonymous/","page":"Anonymous functions","title":"Anonymous functions","text":"In this simple example you won't see any measurable performance penalty associated to this type-instability, but certainly that can arise in other examples. ","category":"page"},{"location":"benchmark/#Benchmarking","page":"Benchmark","title":"Benchmarking","text":"","category":"section"},{"location":"benchmark/#Simple-functions","page":"Benchmark","title":"Simple functions","text":"","category":"section"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"In general, function can be benchmarked with the BenchmarkTools package:","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"using BenchmarkTools\n@btime f($x)\n","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"or","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"@benchmark f($x)","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"It is important to interpolate the variables of the input function, with the $. This is because the macros will then expand the variables into their values on parsing the expression, and the time for that operation does not affect the benchmark anymore.   ","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"The macros @btime and @benchmark generally sample the execution of the function multiple times. Each sample is composed of many function evaluations, and many samples are performed. Care must be taken if you see times smaller than a few tenths of nano-seconds. You might be being tricked by compiler optimizations. For example,","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"julia> function mysum(x,n)\n           s = 0\n           for i in 1:n\n               s += x\n           end\n           s\n       end\n\njulia> @btime mysum(1,10)\n  1.750 ns (0 allocations: 0 bytes)\n10\n\njulia> @btime mysum(1,10_000_000)\n  1.750 ns (0 allocations: 0 bytes)\n10000000\n","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"clearly the second execution is not doing anything more than the first.  The compiler has realized that doing that loop is not optimal and just performs a multiplication.  ","category":"page"},{"location":"benchmark/#Functions-that-modify-their-arguments","page":"Benchmark","title":"Functions that modify their arguments","text":"","category":"section"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"Since for each benchmark the function is executed multiple times, things can become tricky if the time required for the execution is dependent on the values of the arguments. These will be changed by the benchmark itself, affecting the outcome.  ","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"For example, the function below receives to vectors, x and n as parameters, and modifies the two vectors. ","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"function f!(x,n)\n  n[1] = n[1] + 1\n  x[n[1]] = 0\nend","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"A normal execution of this function would be:","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"julia> n = [1];\n\njulia> x = [1,2];\n\njulia> f!(x,n);\n\njulia> x\n2-element Array{Int64,1}:\n 1\n 0\n\njulia> n\n1-element Array{Int64,1}:\n 2\n","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"The function has modified the vectors and, particular, the vector n has now the element 2. If we now execute the same function again, we get an error, because inside the function the element n[1] will assume the value of 3, and the vector x only has two positions:","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"julia> f!(x,n)\nERROR: BoundsError: attempt to access 2-element Array{Int64,1} at index [3]\n","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"Therefore, this function cannot be executed twice in a row without redefining the vector n with n[1]=1. This creates a difficulty for running benchmarks:","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"julia> n = [1];\n\njulia> x = [1,2];\n\njulia> @btime f!(x,n)\nERROR: BoundsError: attempt to access 2-element Array{Int64,1} at index [3]\n","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"This is the same error as before, since @btime tried to execute the function multiple times consecutively. ","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"To address that, we need to explicitly specify that we need each sample of the benchmark to have a single function evaluation, and that the vectors need to be reinitialized before each sample:","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"julia> @btime f!($x,n) setup=(n=[1]) evals=1\n  51.000 ns (0 allocations: 0 bytes)\n2-element Array{Int64,1}:\n 1\n 0\n","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"The setup command defines what has to be initialized, and that initialization does not affect the benchmark. The eval=1 statement defines that each sample will contain a single function evaluation. ","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"Note that, in this case, the n parameter of the function is not interpolated (it does not has the $). ","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"If more than one parameter has to be defined upon initialization, the following syntax is necessary: ","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"julia> @btime f!($x,n,m) setup=(n=[1]; m=[3,4,5]) evals=1\n","category":"page"},{"location":"#JuliaNotes","page":"Home","title":"JuliaNotes","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A collection of explanations and tips to make the best use of Julia.  Many answers are extracts from solutions provided to user questions in the Julia Discourse. ","category":"page"},{"location":"loopscopes/#Scope-behavior-of-loops","page":"Scope of loops","title":"Scope behavior of loops","text":"","category":"section"},{"location":"loopscopes/","page":"Scope of loops","title":"Scope of loops","text":"You will find long and exhaustive threads discussing how Julia ended up with the current scoping rules and behavior, and why it is a good compromise between the pros and cons of many other alternatives. Just search for \"scoping rules\" in the Discourse forum.","category":"page"},{"location":"loopscopes/","page":"Scope of loops","title":"Scope of loops","text":"My perhaps didactic explanation on the choices made is below. I understand that scopes, at least in this context, can be understood as blocks of code that can be compiled and executed independently. One wants the compiler to have as much information as possible concerning the variables of that code block, such that it can specialize the code to the types of variables inside the block. With that image in mind, we have: ","category":"page"},{"location":"loopscopes/","page":"Scope of loops","title":"Scope of loops","text":"Ideally one would like that a loop like \ns = 0\nfor i in 1:3\n    s = s + i\nend\nworked always and modified s as intended. Yet, in Julia, for performance reasons, the for loop introduces a new scope, where the variables may be inferred by the compiler to remain with constant types during the loop execution. If the variable s is global, that means that its type can be changed from outside the loop.  Therefore, writing a loop that makes reference to a global variable cannot be simply accepted without notice. \nThere is no problem in writing such a loop inside a function, because there the types of the variables are constant except if modified by some operation inside the function itself. If they are not, the compiler can realize that and the loop is fast. No problems there.\nThat loop written in the global scope will be problematic (slow) because s might not have a constant type. That is, since the type of s can change outside the loop, the compiler cannot specialize the operations of the loop to the type of s. Thus, one should warn the user that that is not a good programming style. Previously, because of that, it was required that the use of the global variable was explicit:\njulia> s = 0\n       for i in 1:3\n           global s\n           s = s + i\n       end\nHowever, this was inconvenient, because one was not able to copy and paste a code from a function to the REPL. Thus, since Julia 1.5, it was decided that at the REPL the code without the explicit global s declaration will work. The s variable is still global and the loop will not be efficient, but this in this context it is acceptable because nobody writes critical code directly to the REPL.\nThat leaves the possibility of writing such loops inside files, outside functions. For example, defining a file myloop.jl with that loop coded directly inside it, and executing the code in the global scope with: \njulia> include(\"./myloop.jl\")\nA programmer can be tempted to write critical code inside a file in such a way and, while that is not impossible, it must be discouraged. Thus, the choice was to raise a Warning and an Error associated with the possible scoping problems of that loop if it is written as if it was in the global scope of that file: \njulia> include(\"./myloop.jl\")\n┌ Warning: Assignment to `s` in soft scope is ambiguous because a global\nvariable by the same name exists: `s` will be treated as a new local.\nDisambiguate by using `local s` to suppress this warning or `global s`\nto assign to the existing global variable.\n└ @ ~/Drive/Work/JuliaPlay/myloop.jl:3\nERROR: LoadError: UndefVarError: s not defined\nThe warning is clear and is saying: don't  do that, unless you are really really aware of its consequences, and in that case declare s as global explicitly.","category":"page"}]
}
